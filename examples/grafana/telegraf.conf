# Telegraf Configuration for MQTT Sensor Dashboard
# 
# This configuration collects sensor data from MQTT broker and stores it in InfluxDB
# for visualization in Grafana.
#
# Installation:
#   sudo cp telegraf.conf /etc/telegraf/telegraf.conf
#   sudo systemctl restart telegraf
#
# Requirements:
#   - MQTT broker running on localhost:1883
#   - InfluxDB 2.x running on localhost:8086
#   - MQTT messages published to "iot_logger" topic in expected JSON format

# =============================================================================
# GLOBAL AGENT CONFIGURATION
# =============================================================================

[agent]
  ## Default data collection interval for all inputs
  interval = "1s"
  
  ## Rounds collection interval to 'interval'
  round_interval = true
  
  ## Telegraf will send metrics to outputs in batches of at most
  ## metric_batch_size metrics.
  metric_batch_size = 1000
  
  ## Maximum number of unwritten metrics per output.
  metric_buffer_limit = 10000
  
  ## Collection jitter is used to jitter the collection by a random amount.
  collection_jitter = "0s"
  
  ## Default flushing interval for all outputs.
  flush_interval = "1s"
  
  ## Jitter the flush interval by a random amount.
  flush_jitter = "0s"
  
  ## Log at debug level.
  # debug = true
  
  ## Log only error level messages.
  # quiet = false
  
  ## Override default hostname, if empty use os.Hostname()
  hostname = ""
  
  ## If set to true, do no set the "host" tag in the telegraf agent.
  omit_hostname = false

# =============================================================================
# INPUT PLUGINS
# =============================================================================

# Read metrics from MQTT topic(s)
[[inputs.mqtt_consumer]]
  ## MQTT broker URLs to connect to
  servers = ["tcp://localhost:1883"]
  
  ## Topics to subscribe to
  topics = ["iot_logger"]
  
  ## QoS policy for messages
  ## 0 = at most once
  ## 1 = at least once
  ## 2 = exactly once
  qos = 0
  
  ## Connection timeout
  connection_timeout = "30s"
  
  ## Maximum messages to read from the broker that have not been written by an
  ## output before waiting until it is written.
  max_undelivered_messages = 1000
  
  ## Persistent session configuration
  ## Useful for when QoS > 0
  # client_id = ""
  # persistent_session = false
  
  ## Data format to consume
  data_format = "json"
  
  ## Tag keys to extract from JSON
  # tag_keys = []
  
  ## Override measurement name
  name_override = "sensors"

# =============================================================================
# PROCESSOR PLUGINS - Custom Data Processing
# =============================================================================

# Calculate derived metrics using Starlark
[[processors.starlark]]
  ## Starlark script for custom metric processing
  ## This script:
  ##   1. Calculates air quality score from BME680 gas resistance and humidity
  ##   2. Calculates magnetic field magnitude from MMC5983 3-axis data
  ##   3. Detects magnets using robust MAD-based anomaly detection with hysteresis
  ##   4. Determines person presence from STHS34PF80 sensor
  
  source = '''
# Global state for baseline calculations
# Note: This state persists across invocations within the same Telegraf process
state = {
    # Air quality baseline (BME680)
    "gas_samples": [],
    "gas_baseline": None,
    "hum_baseline": 40.0,
    "hum_weighting": 0.25,
    
    # MAD-based magnet detection (MMC5983)
    # Only clean (non-detection) samples enter the baseline buffer,
    # preventing drift when a magnet stays nearby.
    "mag_clean_history": [],       # Clean samples for robust baseline
    "mag_baseline_max": 50,        # Max clean samples to keep
    "mag_min_samples": 10,         # Calibration phase length
    "mag_detection_sigma": 5.0,    # Sigma threshold to trigger detection
    "mag_release_sigma": 3.0,      # Sigma threshold to release (hysteresis)
    "mag_detected": False,         # Current detection state
    "MAD_SCALE_FACTOR": 1.4826,    # MAD-to-sigma for normal distribution
    "MIN_SIGMA": 0.005,            # Floor to avoid division by zero
}

def starlark_abs(x):
    """Absolute value (Starlark has no built-in abs)."""
    if x < 0:
        return -x
    return x

def starlark_median(data):
    """Median of a non-empty list of numbers."""
    s = sorted(data)
    n = len(s)
    mid = n // 2
    if n % 2 == 0:
        return (s[mid - 1] + s[mid]) / 2.0
    return float(s[mid])

def starlark_mad(data, median_val):
    """Median Absolute Deviation: median(|x_i - median|)."""
    devs = []
    for x in data:
        devs.append(starlark_abs(x - median_val))
    return starlark_median(devs)

def apply(metric):
    """
    Process incoming metrics and add calculated fields
    
    Args:
        metric: Input metric from MQTT
        
    Returns:
        Modified metric with additional calculated fields
    """
    
    # =========================================================================
    # BME680: Air Quality Calculation
    # =========================================================================
    # Based on gas resistance and humidity, calculate air quality score (0-100)
    # Implements same algorithm as sensor_plugins/bme680_plugin.py
    
    gas_key = "BME68x_Gas Resistance"
    hum_key = "BME68x_Humidity"
    temp_key = "BME68x_TemperatureC"
    
    if gas_key in metric.fields and hum_key in metric.fields:
        gas = float(metric.fields[gas_key])
        hum = float(metric.fields[hum_key])
        
        # Build baseline from last 50 gas resistance samples
        state["gas_samples"].append(gas)
        if len(state["gas_samples"]) > 50:
            state["gas_samples"] = state["gas_samples"][-50:]
        
        # Calculate baseline and air quality after collecting enough samples
        if len(state["gas_samples"]) >= 10:
            # Update gas baseline
            total = 0.0
            for sample in state["gas_samples"]:
                total += sample
            state["gas_baseline"] = total / len(state["gas_samples"])
            
            # Calculate air quality score
            gas_baseline = state["gas_baseline"]
            hum_baseline = state["hum_baseline"]
            hum_weighting = state["hum_weighting"]
            
            gas_offset = gas_baseline - gas
            hum_offset = hum - hum_baseline
            
            # Humidity score (0-25 with default weighting)
            if hum_offset > 0:
                denominator = 100.0 - hum_baseline
                if denominator > 0:
                    hum_score = ((100.0 - hum_baseline - hum_offset) / denominator) * (hum_weighting * 100.0)
                else:
                    hum_score = 0.0
            else:
                if hum_baseline > 0:
                    hum_score = ((hum_baseline + hum_offset) / hum_baseline) * (hum_weighting * 100.0)
                else:
                    hum_score = 0.0
            
            # Gas score (0-75 with default weighting)
            if gas_offset > 0 and gas_baseline > 0:
                gas_score = (gas / gas_baseline) * (100.0 - (hum_weighting * 100.0))
            else:
                gas_score = 100.0 - (hum_weighting * 100.0)
            
            # Total air quality (0-100, higher is better)
            air_quality = hum_score + gas_score
            
            # Clamp to valid range
            if air_quality < 0:
                air_quality = 0.0
            elif air_quality > 100:
                air_quality = 100.0
            
            # Add calculated fields
            metric.fields["air_quality_score"] = air_quality
            metric.fields["gas_baseline"] = gas_baseline
    
    # =========================================================================
    # MMC5983: Magnetic Field Magnitude & Magnet Detection
    # =========================================================================
    # Calculate 3D magnitude and detect nearby magnets using robust MAD-based
    # anomaly detection with conditional baseline updates and hysteresis.
    # Implements same algorithm as sensor_plugins/magnet_detector.py
    
    mag_x_key = "MMC5983_X Field (Gauss)"
    mag_y_key = "MMC5983_Y Field (Gauss)"
    mag_z_key = "MMC5983_Z Field (Gauss)"
    
    if mag_x_key in metric.fields and mag_y_key in metric.fields and mag_z_key in metric.fields:
        x = float(metric.fields[mag_x_key])
        y = float(metric.fields[mag_y_key])
        z = float(metric.fields[mag_z_key])
        
        # Calculate 3D magnitude (using manual square root since Starlark doesn't support **)
        mag_squared = x*x + y*y + z*z
        # Newton's method for square root (5 iterations for good accuracy)
        magnitude = mag_squared  # initial guess
        if mag_squared > 0:
            magnitude = mag_squared / 2.0
            for i in range(5):
                if magnitude > 0:
                    magnitude = (magnitude + mag_squared / magnitude) / 2.0
        metric.fields["mag_magnitude"] = magnitude
        
        clean_history = state["mag_clean_history"]
        min_samples = state["mag_min_samples"]
        baseline_max = state["mag_baseline_max"]
        detection_sigma = state["mag_detection_sigma"]
        release_sigma = state["mag_release_sigma"]
        mad_scale = state["MAD_SCALE_FACTOR"]
        min_sigma = state["MIN_SIGMA"]
        
        # --- Calibration phase: always accept samples ---
        if len(clean_history) < min_samples:
            clean_history.append(magnitude)
            if len(clean_history) > baseline_max:
                clean_history = clean_history[-baseline_max:]
            state["mag_clean_history"] = clean_history
            
            baseline = starlark_median(clean_history)
            metric.fields["mag_baseline"] = baseline
            metric.fields["mag_z_score"] = 0.0
            metric.fields["magnet_detected"] = 0
        else:
            # --- Compute robust statistics on clean baseline ---
            baseline = starlark_median(clean_history)
            mad = starlark_mad(clean_history, baseline)
            sigma = mad * mad_scale
            if sigma < min_sigma:
                sigma = min_sigma
            
            # Bi-directional robust z-score
            z_score = starlark_abs(magnitude - baseline) / sigma
            
            # --- State machine with hysteresis (Schmitt trigger) ---
            detected = state["mag_detected"]
            if detected:
                if z_score < release_sigma:
                    # Field returned to normal - release detection
                    detected = False
                    clean_history.append(magnitude)
                    if len(clean_history) > baseline_max:
                        clean_history = clean_history[-baseline_max:]
            else:
                if z_score > detection_sigma:
                    # Significant deviation - trigger detection
                    detected = True
                else:
                    # Normal reading - update baseline
                    clean_history.append(magnitude)
                    if len(clean_history) > baseline_max:
                        clean_history = clean_history[-baseline_max:]
            
            state["mag_detected"] = detected
            state["mag_clean_history"] = clean_history
            
            metric.fields["mag_baseline"] = baseline
            metric.fields["mag_z_score"] = z_score
            if detected:
                metric.fields["magnet_detected"] = 1
            else:
                metric.fields["magnet_detected"] = 0
    
    # =========================================================================
    # STHS34PF80: Person Detection
    # =========================================================================
    # Determine if person is present based on presence/motion values
    # Implements same logic as sensor_plugins/mqtt_plugin.py
    
    presence_key = "STHS34PF80_Presence (cm^-1)"
    motion_key = "STHS34PF80_Motion (LSB)"
    
    if presence_key in metric.fields or motion_key in metric.fields:
        presence_threshold = 1000
        person_detected = 0
        
        if presence_key in metric.fields and motion_key in metric.fields:
            presence = float(metric.fields[presence_key])
            motion = float(metric.fields[motion_key])
            if presence >= presence_threshold or motion > 0:
                person_detected = 1
        elif presence_key in metric.fields:
            presence = float(metric.fields[presence_key])
            if presence >= presence_threshold:
                person_detected = 1
        elif motion_key in metric.fields:
            motion = float(metric.fields[motion_key])
            if motion > 0:
                person_detected = 1
        
        metric.fields["person_detected"] = person_detected
    
    return metric
'''

# =============================================================================
# OUTPUT PLUGINS
# =============================================================================

# Configuration for sending metrics to InfluxDB 2.x
[[outputs.influxdb_v2]]
  ## The URLs of the InfluxDB cluster nodes.
  urls = ["http://localhost:8086"]
  
  ## Token for authentication.
  ## IMPORTANT: Replace with your actual InfluxDB token
  ## Generate token in InfluxDB UI: Data > Tokens > Generate Token
  token = "$INFLUX_TOKEN"
  
  ## Organization is the name of the organization you wish to write to.
  organization = "sensors"
  
  ## Destination bucket to write into.
  bucket = "sensor_data"
  
  ## Timeout for HTTP messages.
  timeout = "5s"
  
  ## HTTP User-Agent
  user_agent = "telegraf"
  
  ## Additional HTTP headers
  # http_headers = {"X-Special-Header" = "Special-Value"}
  
  ## HTTP Proxy support
  # http_proxy = "http://localhost:8888"
  
  ## Optional TLS Config for use on HTTP connections.
  # tls_ca = "/etc/telegraf/ca.pem"
  # tls_cert = "/etc/telegraf/cert.pem"
  # tls_key = "/etc/telegraf/key.pem"
  ## Use TLS but skip chain & host verification
  # insecure_skip_verify = false

# =============================================================================
# OPTIONAL: File output for debugging
# =============================================================================
# Uncomment to write metrics to a file for troubleshooting

# [[outputs.file]]
#   ## Files to write to, "stdout" is a specially handled file.
#   files = ["stdout"]
#   
#   ## Data format to output.
#   data_format = "influx"
